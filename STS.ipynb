{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "STS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73zHEsqbhpLW"
      },
      "source": [
        "Importing the required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiYH5nTLQ8wB"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import keras\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "from keras.layers import Conv1D, MaxPooling1D, Dense, Activation, Input, LSTM, Embedding,Lambda, Bidirectional\n",
        "\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keojVD6oM3TL"
      },
      "source": [
        "Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0uMh4xAgrC1",
        "outputId": "e5dca054-6a84-4c69-da40-b8b180a79a9b"
      },
      "source": [
        "!curl -LO https://raw.githubusercontent.com/MohamadMerchant/SNLI/master/data.tar.gz\n",
        "!tar -xvzf data.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 11.1M  100 11.1M    0     0  12.0M      0 --:--:-- --:--:-- --:--:-- 12.0M\n",
            "SNLI_Corpus/\n",
            "SNLI_Corpus/snli_1.0_dev.csv\n",
            "SNLI_Corpus/snli_1.0_train.csv\n",
            "SNLI_Corpus/snli_1.0_test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CYo83dvoL1R"
      },
      "source": [
        "df_train = pd.read_csv(\"SNLI_Corpus/snli_1.0_train.csv\")\n",
        "df_dev = pd.read_csv(\"SNLI_Corpus/snli_1.0_dev.csv\")\n",
        "df_test = pd.read_csv(\"SNLI_Corpus/snli_1.0_test.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhoaYoT1M9kW"
      },
      "source": [
        "Preprocessing the Data:\n",
        "\n",
        "\n",
        "~ Dropping rows missing values\n",
        "\n",
        "~ Extracting one-hot vectors from the similarity column "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4t75ykToaVM",
        "outputId": "a7506277-bb81-4e49-d2f2-838991ebe961"
      },
      "source": [
        "len(df_train)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "550152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bkRZbk1o9RU",
        "outputId": "fd322994-d540-4e77-9967-ea2025e6cf16"
      },
      "source": [
        "df_train.isnull().sum()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "similarity    0\n",
              "sentence1     0\n",
              "sentence2     6\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaRr5tXKpFkB"
      },
      "source": [
        "df_train.dropna(axis=0, inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azQczK1fpZGD",
        "outputId": "3e056431-34e1-4598-af7e-ed4dbd666b6a"
      },
      "source": [
        "df_train.similarity.value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "entailment       183414\n",
              "contradiction    183185\n",
              "neutral          182762\n",
              "-                   785\n",
              "Name: similarity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlQfP8CUpdPT"
      },
      "source": [
        "df_train = (df_train[df_train.similarity != \"-\"].sample(frac=1.0, random_state=42).reset_index(drop=True))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU-Eac-Irj_1"
      },
      "source": [
        "df_train[\"label\"] = df_train[\"similarity\"].apply(lambda x: 0 if x == \"contradiction\" else 1 if x == \"entailment\" else 2)\n",
        "y_train = tf.keras.utils.to_categorical(df_train.label, num_classes=3)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3Ttl6hQpIhD",
        "outputId": "ac8d7a3c-6b81-4662-f616-fbba43bcc3dd"
      },
      "source": [
        "len(df_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "549361"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "JcyhaZY0is4W",
        "outputId": "b2717714-2db5-4768-d8a5-58b4e36192ee"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similarity</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>A woman plays a violin outdoors.</td>\n",
              "      <td>The ball room dancer slipped on a banana peel.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>entailment</td>\n",
              "      <td>The red panted cyclist is amongst nature.</td>\n",
              "      <td>The cyclist is outdoors.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>A bicyclist is doing a trick in midair.</td>\n",
              "      <td>The bicycle is slowly rolling down the straight.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>entailment</td>\n",
              "      <td>Two motorcyclists racing neck and neck around ...</td>\n",
              "      <td>The two motorcyclists are racing each other.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>A middle-age man in black suit speaking into t...</td>\n",
              "      <td>a guy is dancing on a table</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      similarity  ... label\n",
              "0  contradiction  ...     0\n",
              "1     entailment  ...     1\n",
              "2  contradiction  ...     0\n",
              "3     entailment  ...     1\n",
              "4  contradiction  ...     0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IshXqH7rog4L",
        "outputId": "0bbb2ffc-9059-4969-8735-078f720d1b51"
      },
      "source": [
        "len(df_dev)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dgpOM_ppLh8",
        "outputId": "2557cfcb-c61a-4b88-a30f-5c260b7490e6"
      },
      "source": [
        "df_dev.isnull().sum()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "similarity    0\n",
              "sentence1     0\n",
              "sentence2     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zsflnlajphri",
        "outputId": "6688b5f9-16bb-4e8e-8150-f33279058c93"
      },
      "source": [
        "df_dev.similarity.value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "entailment       3329\n",
              "contradiction    3278\n",
              "neutral          3235\n",
              "-                 158\n",
              "Name: similarity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUlqa1pgp-vL"
      },
      "source": [
        "df_dev = (df_dev[df_dev.similarity != \"-\"].sample(frac=1.0, random_state=42).reset_index(drop=True))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvlGzPfFrxpy"
      },
      "source": [
        "df_dev[\"label\"] = df_dev[\"similarity\"].apply(lambda x: 0 if x == \"contradiction\" else 1 if x == \"entailment\" else 2)\n",
        "y_dev = tf.keras.utils.to_categorical(df_dev.label, num_classes=3)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC-SfoXRqCiv",
        "outputId": "e1c735a5-87b7-451b-c0dd-a92ac22594ac"
      },
      "source": [
        "len(df_dev)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9842"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fjSFm2rGu3Es",
        "outputId": "6bb995c1-c897-42b6-c266-c9f4dce10927"
      },
      "source": [
        "df_dev.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similarity</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>A balding man with a checkered shirt and khaki...</td>\n",
              "      <td>A man run in playground.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>The Raiders complete the pass while the Dolphi...</td>\n",
              "      <td>The player is alone asleep in the bathtub.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>A lady sitting on a bench that is against a bu...</td>\n",
              "      <td>Nobody is sitting</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>a man is swimming inside of a pool</td>\n",
              "      <td>there is a person drowning.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>A boy with a basketballs glowers at the camera.</td>\n",
              "      <td>The boy is smiling</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      similarity  ... label\n",
              "0  contradiction  ...     0\n",
              "1  contradiction  ...     0\n",
              "2  contradiction  ...     0\n",
              "3  contradiction  ...     0\n",
              "4  contradiction  ...     0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM7RBaZ9ojjn",
        "outputId": "5909f064-d111-4295-ce55-c7dc090abab2"
      },
      "source": [
        "len(df_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYA-L9Z9pRIq",
        "outputId": "50edb22f-a2cd-4130-abcf-820b92e00156"
      },
      "source": [
        "df_test.isnull().sum()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "similarity    0\n",
              "sentence1     0\n",
              "sentence2     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7juGpH43pmVT",
        "outputId": "c1ad694e-0586-4ce3-9c99-48f36300f35b"
      },
      "source": [
        "df_test.similarity.value_counts()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "entailment       3368\n",
              "contradiction    3237\n",
              "neutral          3219\n",
              "-                 176\n",
              "Name: similarity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03PZqNoIqG7a"
      },
      "source": [
        "df_test = (df_test[df_test.similarity != \"-\"].sample(frac=1.0, random_state=42).reset_index(drop=True))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLzXbrOar8eC"
      },
      "source": [
        "df_test[\"label\"] = df_test[\"similarity\"].apply(lambda x: 0 if x == \"contradiction\" else 1 if x == \"entailment\" else 2)\n",
        "y_test = tf.keras.utils.to_categorical(df_test.label, num_classes=3)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c15GvHeSqTtx",
        "outputId": "60265183-7a5b-4d0a-fb64-36b56c85c540"
      },
      "source": [
        "len(df_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9824"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fVCrFvuqu6Tx",
        "outputId": "0f699b65-6d3f-468f-9d74-1956bf105fe7"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similarity</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>entailment</td>\n",
              "      <td>A person in sunglasses, a scarf, a shirt, and ...</td>\n",
              "      <td>A person standing</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>A person in a green robe sits on a couch with ...</td>\n",
              "      <td>a man sits on a couch</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Three women are sitting on a green bench looki...</td>\n",
              "      <td>The three women are best friends.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>This is when daddy taught her how to ride her ...</td>\n",
              "      <td>the daddy is dead</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>There are five singers on a stage, three women...</td>\n",
              "      <td>The performers are playing bagpipes.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      similarity  ... label\n",
              "0     entailment  ...     1\n",
              "1        neutral  ...     2\n",
              "2        neutral  ...     2\n",
              "3  contradiction  ...     0\n",
              "4  contradiction  ...     0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIPOgr0KPXo3"
      },
      "source": [
        "One can try to extract these similarity scores by using Pre-Trained models like BERT and Universal Sentence Encoder to extract sentence level embeddings and calculating a similarity metric, for eg the cosine similarity, and scaling it to the output range.\n",
        "\n",
        "\n",
        "However, the drawback of this approach is that:\n",
        "\n",
        "~ BERT can handle a maximum of 512 tokens in one text and if the input is larger than that it needs to be cropped in some way which might result in loss of information usefull for determining semantic meaning.\n",
        "\n",
        "~ In case of Universal Sentence Encoder as the input text becomes larger the encoding becomes less representative and this again might result in loss of information important for determining semantic meaning.\n",
        "\n",
        "\n",
        "Therefore, i demonstrate a supervised learning model (making use of pretrained GolVe embeddings, any other embedding of choice may be used) that can scale to any size of the paragraph. \n",
        "\n",
        "The model is in essence a CNN+BiLSTM Siamese Network, followed by calculation of L1 distance that is fed into a Dense layer for prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkNHAKdPie11"
      },
      "source": [
        "Finding the maximum length of the input sentence/paragraph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE4mFmkfMukF",
        "outputId": "838607b9-c8a1-4db5-dff6-045e76410fbe"
      },
      "source": [
        "MAX_LEN = 0\n",
        "for sentence in list(df_train['sentence1']) + list(df_train['sentence2']):\n",
        "  if len(sentence)>MAX_LEN:\n",
        "    MAX_LEN = len(sentence)\n",
        "print(MAX_LEN)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yGm04FwcmMl"
      },
      "source": [
        "Generating the vocabulary for the model.\n",
        "Defining a text vectorizer for tokenization, vectorization of input sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLiIaHWccLtz"
      },
      "source": [
        "vectorizer = TextVectorization(output_sequence_length = MAX_LEN)\n",
        "\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(list(df_train['sentence1']) + list(df_train['sentence2'])).batch(10)\n",
        "\n",
        "vectorizer.adapt(text_ds)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCHKHGzv4Imu",
        "outputId": "461bb914-354b-457b-8ce9-aa63f9665f70"
      },
      "source": [
        "#print length of vocabulary\n",
        "len(vectorizer.get_vocabulary())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35972"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HWUmtQic6ty"
      },
      "source": [
        "Generating mapping from word to index of word in the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amKg33Yhswna"
      },
      "source": [
        "vocabulary = vectorizer.get_vocabulary()\n",
        "\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SEAhRu8dA0j"
      },
      "source": [
        "Downloading and extracting the Pre-Trained GloVe embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd9zZdBjM05z",
        "outputId": "6f684e66-09d1-4d6b-f7e0-03d8e2051d2e"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "!unzip -q glove.840B.300d.zip"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-05 10:23:24--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2021-06-05 10:23:24--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2021-06-05 10:23:24--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  5.01MB/s    in 6m 51s  \n",
            "\n",
            "2021-06-05 10:30:15 (5.06 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guCfWVN3tAft"
      },
      "source": [
        "path_to_glove_file = \"glove.840B.300d.txt\""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gteJeE8FdNmF"
      },
      "source": [
        "Generating a mapping from word to GloVe embedding of the word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XuGk8AGuA3Q"
      },
      "source": [
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coef = coefs\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        if coefs.shape == (0,) and word not in embeddings_index:\n",
        "          for i in range(len(coef)):\n",
        "            try:\n",
        "              x = int(coef[i])\n",
        "              break\n",
        "            except:\n",
        "              pass\n",
        "          coefs = np.fromstring(coef[i:], \"f\", sep=\" \")\n",
        "        if coefs.shape != (0,):\n",
        "          embeddings_index[word] = coefs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g2IuclGd9SA"
      },
      "source": [
        "Preparing the embedding matrix (matrix[i] holds the embedding of i'th word in the vocabulary). Words in the vocabulary not found in the Pre-Trained GloVe embeddings are marked as all zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPgEGftQu-zN"
      },
      "source": [
        "num_tokens = len(vocabulary) + 2\n",
        "embedding_dim = 300\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSO5VrfjfGtD"
      },
      "source": [
        "Defining the Semantic Text Similarity extraction model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJipu6DijrZw"
      },
      "source": [
        "def make_STS_model():\n",
        "\n",
        "  #Defining the inputs to the model\n",
        "  input_left = Input(shape=(None,), dtype=\"int64\")\n",
        "  input_right = Input(shape=(None,), dtype=\"int64\")\n",
        "\n",
        "  embedding_layer = Embedding(num_tokens, embedding_dim, embeddings_initializer=keras.initializers.Constant(embedding_matrix), trainable=False)\n",
        "  #Defining the siamese identical subnetwork\n",
        "\n",
        "  #BiLSTM part\n",
        "  lstm_sub_net = Sequential()\n",
        "  lstm_sub_net(Input(shape=(None,)))\n",
        "  lstm_sub_net.add(Bidirectional(LSTM(200,return_sequences=True), input_shape = (None,350)))\n",
        "  lstm_sub_net.add(Bidirectional(LSTM(200)))\n",
        "\n",
        "  #CNN part\n",
        "  sub_net = Sequential()\n",
        "  sub_net.add(Conv1D(50, 9, activation=\"relu\", padding='same', input_shape = (None, 300)))\n",
        "\n",
        "  #Printing the siamese subnetwork summary\n",
        "  print(\"Siamese CNN subnetwork summary:\")\n",
        "  print(sub_net.summary())\n",
        "\n",
        "  print(\"Siamese BiLSTM subnetwork summary:\")\n",
        "  print(lstm_sub_net.summary())\n",
        "\n",
        "  #Extracting embeddings of each input\n",
        "  input_encoded_left = embedding_layer(input_left)\n",
        "  input_encoded_right = embedding_layer(input_right)\n",
        "\n",
        "  #Extracting encoding of text1 and text2 from subnetwork\n",
        "  left_encoding = sub_net(input_encoded_left)\n",
        "  right_encoding = sub_net(input_encoded_right)\n",
        "  left_encoding = lstm_sub_net(tf.concat([input_encoded_left, left_encoding], axis = 2))\n",
        "  right_encoding = lstm_sub_net(tf.concat([input_encoded_right, right_encoding], axis = 2))\n",
        "    \n",
        "  #Defining the predictor network for combining the siamese subnetwork results\n",
        "  L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
        "  L1_distance = L1_layer([left_encoding, right_encoding])\n",
        "  predictor = Sequential()\n",
        "  predictor.add(Dense(3))\n",
        "  predictor.add(Activation('softmax'))\n",
        "  prediction = predictor(L1_distance)\n",
        "\n",
        "  #encapsulating the whole model\n",
        "  model = Model(inputs=[input_left,input_right], outputs=prediction)\n",
        "\n",
        "  #returning the model\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA-OkBs-kTBK"
      },
      "source": [
        "model = make_STS_model()\n",
        "\n",
        "print(\"Model summary:\")\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzgVacoBocYQ"
      },
      "source": [
        "Preprocessing the data (converting words to word indices) and preparing the data for feeding into the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3St-D46nWoK"
      },
      "source": [
        "X_train_1 = vectorizer(np.array([[s] for s in list(df_train['sentence1'])])).numpy()\n",
        "X_train_2 = vectorizer(np.array([[s] for s in list(df_train['sentence2'])])).numpy()\n",
        "X_train = [X_train_1, X_train_2]\n",
        "\n",
        "X_dev_1 = vectorizer(np.array([[s] for s in list(df_dev['sentence1'])])).numpy()\n",
        "X_dev_2 = vectorizer(np.array([[s] for s in list(df_dev['sentence2'])])).numpy()\n",
        "X_dev = [X_dev_1, X_dev_2]\n",
        "\n",
        "X_test_1 = vectorizer(np.array([[s] for s in list(df_test['sentence1'])])).numpy()\n",
        "X_test_2 = vectorizer(np.array([[s] for s in list(df_test['sentence2'])])).numpy()\n",
        "X_test = [X_test_1, X_test_2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHUUn3oW2Urw"
      },
      "source": [
        "Compiling the model (defining loss function, optimizer and performance metrics)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDfnBKf7oJh_"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adamax(learning_rate=0.01), metrics=[\"acc\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyfRhQty2fEM"
      },
      "source": [
        "Defining helper functions for learning rate scheduling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFuYNWBBqbYY"
      },
      "source": [
        "def lr_scheduler(epoch):\n",
        "    return 0.01 * 0.9 ** epoch\n",
        "\n",
        "class LrHistory(keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        print(\"Learning rate:\", K.get_value(model.optimizer.lr))\n",
        "model_filename = 'cifar.{0:03d}.hdf5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd2BxrJk2owp"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDstODzHplJf"
      },
      "source": [
        "model.fit(\n",
        "    X_train, y_train, \n",
        "    batch_size=8, \n",
        "    epochs=5,\n",
        "    callbacks=[keras.callbacks.LearningRateScheduler(lr_scheduler),LrHistory()],\n",
        "    validation_data=(X_dev,y_dev),\n",
        "    shuffle=True,\n",
        "    verbose=1,\n",
        "    initial_epoch = 0\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_gcaQI_17LW"
      },
      "source": [
        "Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CFF6BvI2R7f"
      },
      "source": [
        "model.save('drive/MyDrive/AA/'+model_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGB9fVNq63_o"
      },
      "source": [
        "Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSU_DBAI5VR-"
      },
      "source": [
        "model = keras.models.load_model('drive/MyDrive/AA/'+model_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftggOUhz67EK"
      },
      "source": [
        "Preparing data for evaluation and prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7VIaD621y7L"
      },
      "source": [
        "X_1 = vectorizer(np.array([[s] for s in list(df['text1'])])).numpy()\n",
        "X_2 = vectorizer(np.array([[s] for s in list(df['text2'])])).numpy()\n",
        "X = [X_1, X_2]\n",
        "\n",
        "y = np.expand_dims(np.array(labels), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kbmz8A1YCfxi"
      },
      "source": [
        "Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb2rBG7UBsFe",
        "outputId": "96a06cc4-275b-49eb-d661-9686648eb587"
      },
      "source": [
        "model.evaluate(X, y, batch_size = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "403/403 [==============================] - 1448s 4s/step - loss: 0.0010 - mse: 0.0010 - mape: 3.8174 - cosine_proximity: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0010039163753390312, 0.0010039163753390312, 3.8174126148223877, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWtj_n9LHPDb"
      },
      "source": [
        "As can be seen, there is approximately 3.82% error in prediction after training for 3 epochs. The model has potential for much better performance if trained for a greater number of epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cKoZMfk6_bs"
      },
      "source": [
        "Prediction using the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoFfe3ih6dYB",
        "outputId": "1a6836af-1857-4ed1-92d9-d66186a82196"
      },
      "source": [
        "y_predicted = model.predict(X, batch_size = 10, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "403/403 [==============================] - 1484s 4s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OXNbzrK8rEv"
      },
      "source": [
        "Saving the results as DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "eI7azHDG8aMs",
        "outputId": "9eba34cb-ff1f-4ee2-8be6-c63b2689143b"
      },
      "source": [
        "result_supervised_df = pd.DataFrame(zip(list(df['Unique_ID']),list(np.array(y_predicted).squeeze())), columns = ['Unique_ID', ' Similarity_Score'])\n",
        "\n",
        "result_supervised_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unique_ID</th>\n",
              "      <th>Similarity_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.574880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.596193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.684598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.641111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.607438</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unique_ID   Similarity_Score\n",
              "0          0           0.574880\n",
              "1          1           0.596193\n",
              "2          2           0.684598\n",
              "3          3           0.641111\n",
              "4          4           0.607438"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiOouwO08u1r"
      },
      "source": [
        "Saving the DataFrame to CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfmxOcrw8gY9"
      },
      "source": [
        "result_supervised_df.to_csv('drive/MyDrive/supervised_approach_results.csv', index= False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}